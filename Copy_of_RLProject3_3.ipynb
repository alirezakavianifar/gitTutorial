{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezakavianifar/gitTutorial/blob/developer/Copy_of_RLProject3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gymnasium stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwXSo7gJ7sDb",
        "outputId": "26237a64-8787-4610-cc54-3362b31adb39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GtkwtSU6Aswz",
        "outputId": "258b1096-deac-4c7d-8098-df32f4af9e78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation demand has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation inventory has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation supply_capacity has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.logger import configure\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class HealthcareNetworkEnv(gym.Env):\n",
        "    def __init__(self, H, P, R, T, LeadTime, transport_costs, transshipment_costs, inventory_costs, ordering_costs, coverage_distance, hospital_distances):\n",
        "        super(HealthcareNetworkEnv, self).__init__()\n",
        "\n",
        "        self.H = H\n",
        "        self.P = P\n",
        "        self.R = R\n",
        "        self.T = T\n",
        "        self.LeadTime = LeadTime\n",
        "\n",
        "        self.transport_costs = transport_costs\n",
        "        self.transshipment_costs = transshipment_costs\n",
        "        self.inventory_costs = inventory_costs\n",
        "        self.ordering_costs = ordering_costs\n",
        "\n",
        "        self.coverage_distance = coverage_distance\n",
        "        self.hospital_distances = hospital_distances\n",
        "\n",
        "        self.observation_space = spaces.Dict({\n",
        "            'inventory': spaces.Box(low=0, high=np.inf, shape=(H, P), dtype=np.float32),\n",
        "            'demand': spaces.Box(low=0, high=np.inf, shape=(H, P), dtype=np.float32),\n",
        "            'supply_capacity': spaces.Box(low=0, high=np.inf, shape=(H, P), dtype=np.float32),\n",
        "            'lead_time': spaces.Box(low=0, high=np.inf, shape=(P,), dtype=np.float32)\n",
        "        })\n",
        "\n",
        "        self.action_space = spaces.MultiDiscrete([10] * (H * P * R + H * H * P))\n",
        "        self.state = self.reset()\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        self.state = {\n",
        "            'inventory': np.zeros((self.H, self.P), dtype=np.float32),\n",
        "            'demand': np.random.randint(0, 10, size=(self.H, self.P)).astype(np.float32),\n",
        "            'supply_capacity': np.ones((self.H, self.P), dtype=np.float32),\n",
        "            'lead_time': self.LeadTime.astype(np.float32)\n",
        "        }\n",
        "        self.orders_in_transit = []\n",
        "        self.current_time = 0\n",
        "        return self.state, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        order_action_size = self.H * self.P * self.R\n",
        "        order = np.array(action[:order_action_size]).reshape((self.H, self.P, self.R))\n",
        "        transship = np.array(action[order_action_size:]).reshape((self.H, self.H, self.P))\n",
        "\n",
        "        self._update_inventory(order, transship)\n",
        "        reward, demand_loss, costs = self._calculate_reward(order, transship)\n",
        "        self._update_demand()\n",
        "        next_state = self.state\n",
        "\n",
        "        done = self.current_time >= self.T\n",
        "        truncated = False  # We are not using truncation, so set it to False\n",
        "        self.current_time += 1\n",
        "\n",
        "        return next_state, reward, done, truncated, {}\n",
        "\n",
        "    def _update_inventory(self, order, transship):\n",
        "        new_orders_in_transit = []\n",
        "        for order_info in self.orders_in_transit:\n",
        "            arrival_time, h, p, quantity = order_info\n",
        "            if self.current_time >= arrival_time:\n",
        "                self.state['inventory'][h, p] += quantity\n",
        "            else:\n",
        "                new_orders_in_transit.append(order_info)\n",
        "        self.orders_in_transit = new_orders_in_transit\n",
        "\n",
        "        for h in range(self.H):\n",
        "            for p in range(self.P):\n",
        "                for r in range(self.R):\n",
        "                    supply_received = order[h, p, r]\n",
        "                    capacity_available = self.state['supply_capacity'][h, p]\n",
        "                    supply_received = min(supply_received, capacity_available)\n",
        "                    arrival_time = self.current_time + self.LeadTime[p]\n",
        "                    self.orders_in_transit.append((arrival_time, h, p, supply_received))\n",
        "\n",
        "        for h1 in range(self.H):\n",
        "            for h2 in range(self.H):\n",
        "                if h1 != h2 and self.hospital_distances[h1, h2] <= self.coverage_distance:\n",
        "                    for p in range(self.P):\n",
        "                        if transship[h1, h2, p] > 0:\n",
        "                            transfer_quantity = min(transship[h1, h2, p], self.state['inventory'][h1, p])\n",
        "                            self.state['inventory'][h1, p] -= transfer_quantity\n",
        "                            self.state['inventory'][h2, p] += transfer_quantity\n",
        "\n",
        "        self.state['inventory'] = np.maximum(self.state['inventory'], 0)\n",
        "\n",
        "    def _calculate_reward(self, order, transship):\n",
        "        reward = 0\n",
        "        demand_loss = 0\n",
        "        total_costs = 0\n",
        "\n",
        "        epsilon_p = 0.01\n",
        "\n",
        "        transport_cost = 0\n",
        "        transshipment_cost = 0\n",
        "        inventory_cost = 0\n",
        "        ordering_cost = 0\n",
        "        shortage_cost = 0\n",
        "\n",
        "        for h in range(self.H):\n",
        "            for p in range(self.P):\n",
        "                for r in range(self.R):\n",
        "                    ordered_quantity = order[h, p, r]\n",
        "                    received_quantity = self.state['inventory'][h, p]\n",
        "\n",
        "                    if received_quantity < ordered_quantity * (1 + epsilon_p):\n",
        "                        demand_loss += (ordered_quantity * (1 + epsilon_p) - received_quantity)\n",
        "                    elif received_quantity > ordered_quantity * (1 + epsilon_p):\n",
        "                        demand_loss += (received_quantity - ordered_quantity * (1 + epsilon_p))\n",
        "                    else:\n",
        "                        reward += received_quantity\n",
        "\n",
        "                    transport_cost += ordered_quantity * self.transport_costs[r, h, p]\n",
        "\n",
        "                inventory_cost += self.state['inventory'][h, p] * self.inventory_costs[h, p]\n",
        "                shortage = max(self.state['demand'][h, p] - self.state['inventory'][h, p], 0)\n",
        "                shortage_cost += shortage\n",
        "\n",
        "        for h1 in range(self.H):\n",
        "            for h2 in range(self.H):\n",
        "                if h1 != h2 and self.hospital_distances[h1, h2] <= self.coverage_distance:\n",
        "                    for p in range(self.P):\n",
        "                        transshipment_quantity = transship[h1, h2, p]\n",
        "                        transshipment_cost += transshipment_quantity * self.transshipment_costs[h1, h2, p]\n",
        "\n",
        "        for h in range(self.H):\n",
        "            for p in range(self.P):\n",
        "                ordering_cost += np.sum(order[h, p, :]) * self.ordering_costs[p, h]\n",
        "\n",
        "        total_costs = transport_cost + transshipment_cost + inventory_cost + ordering_cost + shortage_cost\n",
        "        reward = -total_costs\n",
        "\n",
        "        return reward, demand_loss, total_costs\n",
        "\n",
        "    def _update_demand(self):\n",
        "        self.state['demand'] = np.random.randint(0, 10, size=(self.H, self.P)).astype(np.float32)\n",
        "\n",
        "# Define parameters\n",
        "H = 5\n",
        "P = 3\n",
        "R = 1\n",
        "T = 10\n",
        "LeadTime = np.array([1, 2, 3])\n",
        "\n",
        "transport_costs = np.random.rand(R, H, P)\n",
        "transshipment_costs = np.random.rand(H, H, P)\n",
        "inventory_costs = np.random.rand(H, P)\n",
        "ordering_costs = np.random.rand(P, H)\n",
        "coverage_distance = 5.0\n",
        "hospital_distances = np.random.rand(H, H) * 10\n",
        "\n",
        "env = HealthcareNetworkEnv(H, P, R, T, LeadTime, transport_costs, transshipment_costs, inventory_costs, ordering_costs, coverage_distance, hospital_distances)\n",
        "\n",
        "check_env(env)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = DummyVecEnv([lambda: Monitor(env)])\n",
        "\n",
        "log_dir = \"./logs/\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "logger = configure(log_dir, [\"stdout\", \"csv\", \"tensorboard\"])\n",
        "\n",
        "eval_env = DummyVecEnv([lambda: Monitor(HealthcareNetworkEnv(H, P, R, T, LeadTime, transport_costs, transshipment_costs, inventory_costs, ordering_costs, coverage_distance, hospital_distances))])\n",
        "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs/best_model\", log_path=\"./logs/results\", eval_freq=500, deterministic=True, render=False)\n",
        "\n",
        "model = PPO(\"MultiInputPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
        "model.learn(total_timesteps=10000, callback=eval_callback)\n",
        "\n",
        "model.save(\"ppo_healthcare_network\")\n",
        "\n",
        "# To load the trained model and evaluate\n",
        "model = PPO.load(\"ppo_healthcare_network\")\n",
        "\n",
        "obs = env.reset()\n",
        "for i in range(1000):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, rewards, dones, truncated, info = env.step(action)\n",
        "    if dones:\n",
        "        obs = env.reset()\n",
        "\n",
        "print(\"Evaluation completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX3ss3tJydJP",
        "outputId": "1df1af98-b85d-4be5-af42-887e6fcbb9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to ./logs/\n",
            "Using cuda device\n",
            "Logging to ./logs/PPO_1\n",
            "Eval num_timesteps=500, episode_reward=-2160.43 +/- 49.38\n",
            "Episode length: 11.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 11        |\n",
            "|    mean_reward     | -2.16e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 500       |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=1000, episode_reward=-2169.02 +/- 18.51\n",
            "Episode length: 11.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 11        |\n",
            "|    mean_reward     | -2.17e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1000      |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1500, episode_reward=-2158.79 +/- 41.85\n",
            "Episode length: 11.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 11        |\n",
            "|    mean_reward     | -2.16e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1500      |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=2000, episode_reward=-2160.21 +/- 17.67\n",
            "Episode length: 11.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 11        |\n",
            "|    mean_reward     | -2.16e+03 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2000      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 11        |\n",
            "|    ep_rew_mean     | -2.02e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 16        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 122       |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZ-O4hfE8Zsl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}